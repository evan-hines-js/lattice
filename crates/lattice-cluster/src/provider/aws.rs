//! AWS infrastructure provider (CAPA)
//!
//! Generates Cluster API manifests for provisioning Kubernetes clusters on
//! AWS using the CAPA provider. Uses NLB for API server load balancing.

use async_trait::async_trait;
use std::collections::BTreeMap;

use super::{
    build_post_kubeadm_commands, generate_bootstrap_config_template, generate_cluster,
    generate_control_plane, generate_machine_deployment, BootstrapInfo, CAPIManifest,
    ClusterConfig, ControlPlaneConfig, InfrastructureRef, Provider,
};
use crate::{Error, Result};
use lattice_common::crd::{AwsConfig, LatticeCluster, ProviderSpec, ProviderType};

const AWS_API_VERSION: &str = "infrastructure.cluster.x-k8s.io/v1beta2";

/// Configuration for generating an AWS machine template
struct MachineTemplateConfig<'a> {
    name: &'a str,
    aws_cfg: &'a AwsConfig,
    instance_type: &'a str,
    iam_profile: Option<&'a str>,
    root_volume_size: Option<u32>,
    root_volume_type: Option<&'a str>,
    suffix: &'a str,
}

/// AWS infrastructure provider
#[derive(Clone, Debug)]
pub struct AwsProvider {
    namespace: String,
}

impl AwsProvider {
    /// Create a new AWS provider with the given CAPI namespace
    pub fn with_namespace(namespace: &str) -> Self {
        Self {
            namespace: namespace.to_string(),
        }
    }

    fn infra_ref(&self) -> InfrastructureRef<'static> {
        InfrastructureRef {
            api_group: "infrastructure.cluster.x-k8s.io",
            api_version: AWS_API_VERSION,
            cluster_kind: "AWSCluster",
            machine_template_kind: "AWSMachineTemplate",
        }
    }

    fn get_config(cluster: &LatticeCluster) -> Option<&AwsConfig> {
        cluster.spec.provider.config.aws.as_ref()
    }

    /// Generate AWSCluster manifest
    fn generate_aws_cluster(&self, cluster: &LatticeCluster) -> Result<CAPIManifest> {
        let name = cluster
            .metadata
            .name
            .as_ref()
            .ok_or_else(|| Error::validation("cluster name required"))?;
        let cfg =
            Self::get_config(cluster).ok_or_else(|| Error::validation("aws config required"))?;

        let mut spec = serde_json::json!({
            "region": &cfg.region,
            "sshKeyName": &cfg.ssh_key_name
        });

        // VPC configuration - either use existing or let CAPA create one
        if let Some(ref vpc_id) = cfg.vpc_id {
            spec["network"] = serde_json::json!({
                "vpc": {
                    "id": vpc_id
                }
            });

            // Add subnets if configured
            if let Some(ref cp_subnets) = cfg.cp_subnet_ids {
                let subnets: Vec<serde_json::Value> = cp_subnets
                    .iter()
                    .map(|id: &String| serde_json::json!({ "id": id }))
                    .collect();
                if let Some(network) = spec.get_mut("network") {
                    network["subnets"] = serde_json::json!(subnets);
                }
            }
        }

        // Control plane load balancer configuration (NLB by default)
        let lb_type = cfg
            .load_balancer_type
            .clone()
            .unwrap_or_else(|| "nlb".to_string());
        spec["controlPlaneLoadBalancer"] = serde_json::json!({
            "scheme": "internet-facing",
            "loadBalancerType": lb_type
        });

        Ok(CAPIManifest::new(AWS_API_VERSION, "AWSCluster", name, &self.namespace).with_spec(spec))
    }

    /// Generate AWSMachineTemplate manifest
    fn generate_machine_template(&self, cfg: MachineTemplateConfig<'_>) -> CAPIManifest {
        let mut spec = serde_json::json!({
            "instanceType": cfg.instance_type,
            "sshKeyName": &cfg.aws_cfg.ssh_key_name
        });

        // IAM instance profile
        if let Some(profile) = cfg.iam_profile {
            spec["iamInstanceProfile"] = serde_json::json!(profile);
        }

        // AMI configuration
        if let Some(ref ami_id) = cfg.aws_cfg.ami_id {
            spec["ami"] = serde_json::json!({ "id": ami_id });
        }

        // Root volume configuration
        let volume_size = cfg.root_volume_size.unwrap_or(80);
        let volume_type = cfg.root_volume_type.unwrap_or("gp3");
        spec["rootVolume"] = serde_json::json!({
            "size": volume_size,
            "type": volume_type
        });

        // SSH authorized keys for cloud-init
        if let Some(keys) = &cfg.aws_cfg.ssh_authorized_keys {
            if !keys.is_empty() {
                spec["cloudInit"] = serde_json::json!({
                    "insecureSkipSecretsManager": true
                });
            }
        }

        CAPIManifest::new(
            AWS_API_VERSION,
            "AWSMachineTemplate",
            format!("{}-{}", cfg.name, cfg.suffix),
            &self.namespace,
        )
        .with_spec(serde_json::json!({ "template": { "spec": spec } }))
    }
}

#[async_trait]
impl Provider for AwsProvider {
    async fn generate_capi_manifests(
        &self,
        cluster: &LatticeCluster,
        bootstrap: &BootstrapInfo,
    ) -> Result<Vec<CAPIManifest>> {
        let name = cluster
            .metadata
            .name
            .as_ref()
            .ok_or_else(|| Error::validation("cluster name required"))?;
        let spec = &cluster.spec;
        let cfg =
            Self::get_config(cluster).ok_or_else(|| Error::validation("aws config required"))?;

        // Build cluster config
        let mut labels = BTreeMap::new();
        labels.insert("cluster.x-k8s.io/cluster-name".to_string(), name.clone());
        labels.insert("lattice.dev/cluster".to_string(), name.clone());

        let config = ClusterConfig {
            name,
            namespace: &self.namespace,
            k8s_version: &spec.provider.kubernetes.version,
            labels,
            bootstrap: spec.provider.kubernetes.bootstrap.clone(),
            provider_type: ProviderType::Aws,
        };

        // Build certSANs
        let mut cert_sans = spec
            .provider
            .kubernetes
            .cert_sans
            .clone()
            .unwrap_or_default();

        // Add endpoints.host to SANs if configured
        if let Some(ref endpoints) = cluster.spec.parent_config {
            if let Some(ref host) = endpoints.host {
                if !cert_sans.contains(host) {
                    cert_sans.push(host.clone());
                }
            }
        }

        // No kube-vip for AWS - we use NLB
        let cp_config = ControlPlaneConfig {
            replicas: spec.nodes.control_plane,
            cert_sans,
            post_kubeadm_commands: build_post_kubeadm_commands(name, bootstrap),
            vip: None,
            ssh_authorized_keys: cfg.ssh_authorized_keys.clone().unwrap_or_default(),
        };

        let infra = self.infra_ref();

        // Get IAM profiles with CAPA defaults
        let cp_iam = cfg
            .cp_iam_instance_profile
            .as_deref()
            .unwrap_or("control-plane.cluster-api-provider-aws.sigs.k8s.io");
        let worker_iam = cfg
            .worker_iam_instance_profile
            .as_deref()
            .unwrap_or("nodes.cluster-api-provider-aws.sigs.k8s.io");

        Ok(vec![
            generate_cluster(&config, &infra),
            self.generate_aws_cluster(cluster)?,
            generate_control_plane(&config, &infra, &cp_config),
            self.generate_machine_template(MachineTemplateConfig {
                name,
                aws_cfg: cfg,
                instance_type: &cfg.cp_instance_type,
                iam_profile: Some(cp_iam),
                root_volume_size: cfg.cp_root_volume_size_gb,
                root_volume_type: cfg.cp_root_volume_type.as_deref(),
                suffix: "control-plane",
            }),
            generate_machine_deployment(&config, &infra),
            self.generate_machine_template(MachineTemplateConfig {
                name,
                aws_cfg: cfg,
                instance_type: &cfg.worker_instance_type,
                iam_profile: Some(worker_iam),
                root_volume_size: cfg.worker_root_volume_size_gb,
                root_volume_type: cfg.worker_root_volume_type.as_deref(),
                suffix: "md-0",
            }),
            generate_bootstrap_config_template(&config),
        ])
    }

    async fn validate_spec(&self, spec: &ProviderSpec) -> Result<()> {
        let version = &spec.kubernetes.version;
        if !version.starts_with("1.") && !version.starts_with("v1.") {
            return Err(Error::validation(format!(
                "invalid kubernetes version: {version}, expected format: 1.x.x or v1.x.x"
            )));
        }

        // Validate AWS-specific config
        if let Some(ref cfg) = spec.config.aws {
            if cfg.region.is_empty() {
                return Err(Error::validation("aws config requires region"));
            }
            if cfg.cp_instance_type.is_empty() {
                return Err(Error::validation("aws config requires cpInstanceType"));
            }
            if cfg.worker_instance_type.is_empty() {
                return Err(Error::validation("aws config requires workerInstanceType"));
            }
            if cfg.ssh_key_name.is_empty() {
                return Err(Error::validation("aws config requires sshKeyName"));
            }

            // Validate VPC configuration consistency
            if cfg.vpc_id.is_some() && cfg.cp_subnet_ids.is_none() {
                return Err(Error::validation(
                    "aws config requires cpSubnetIds when vpcId is specified",
                ));
            }
        }

        Ok(())
    }

    fn required_secrets(&self, cluster: &LatticeCluster) -> Vec<(String, String)> {
        // Use credentials_secret_ref from ProviderSpec if set, otherwise use default
        let secret_ref = cluster.spec.provider.credentials_secret_ref.as_ref();
        vec![(
            secret_ref
                .map(|s| s.name.clone())
                .unwrap_or_else(|| "capa-manager-bootstrap-credentials".to_string()),
            secret_ref
                .map(|s| s.namespace.clone())
                .unwrap_or_else(|| "capa-system".to_string()),
        )]
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use kube::api::ObjectMeta;
    use lattice_common::crd::LatticeClusterSpec;
    use lattice_common::crd::{
        BootstrapProvider, KubernetesSpec, NodeSpec, ProviderConfig, ProviderSpec,
    };

    fn test_aws_config() -> AwsConfig {
        AwsConfig {
            region: "us-west-2".to_string(),
            cp_instance_type: "m5.xlarge".to_string(),
            worker_instance_type: "m5.large".to_string(),
            ssh_key_name: "lattice-key".to_string(),
            ..Default::default()
        }
    }

    fn test_cluster(name: &str) -> LatticeCluster {
        LatticeCluster {
            metadata: ObjectMeta {
                name: Some(name.to_string()),
                namespace: Some("default".to_string()),
                ..Default::default()
            },
            spec: LatticeClusterSpec {
                provider: ProviderSpec {
                    kubernetes: KubernetesSpec {
                        version: "1.32.0".to_string(),
                        cert_sans: None,
                        bootstrap: BootstrapProvider::Kubeadm,
                    },
                    config: ProviderConfig::aws(test_aws_config()),
                    credentials_secret_ref: None,
                },
                nodes: NodeSpec {
                    control_plane: 3,
                    workers: 5,
                },
                parent_config: None,
                networking: None,
                environment: None,
                region: None,
                workload: None,
            },
            status: None,
        }
    }

    #[tokio::test]
    async fn generates_seven_manifests() {
        let provider = AwsProvider::with_namespace("capi-system");
        let manifests = provider
            .generate_capi_manifests(&test_cluster("test"), &BootstrapInfo::default())
            .await
            .expect("manifest generation should succeed");

        // 7 manifests: Cluster, AWSCluster, ControlPlane, 2x MachineTemplate, MachineDeployment, ConfigTemplate
        assert_eq!(manifests.len(), 7);
        let kinds: Vec<_> = manifests.iter().map(|m| m.kind.as_str()).collect();
        assert!(kinds.contains(&"Cluster"));
        assert!(kinds.contains(&"AWSCluster"));
        assert!(kinds.contains(&"KubeadmControlPlane"));
        assert!(kinds.contains(&"AWSMachineTemplate"));
        assert!(kinds.contains(&"MachineDeployment"));
        assert!(kinds.contains(&"KubeadmConfigTemplate"));
    }

    #[tokio::test]
    async fn uses_nlb_by_default() {
        let provider = AwsProvider::with_namespace("capi-system");
        let manifests = provider
            .generate_capi_manifests(&test_cluster("test"), &BootstrapInfo::default())
            .await
            .expect("manifest generation should succeed");

        let aws_cluster = manifests
            .iter()
            .find(|m| m.kind == "AWSCluster")
            .expect("AWSCluster should exist");
        let lb_type = &aws_cluster.spec.as_ref().expect("spec should exist")
            ["controlPlaneLoadBalancer"]["loadBalancerType"];
        assert_eq!(lb_type, "nlb");
    }

    #[tokio::test]
    async fn validates_kubernetes_version() {
        let provider = AwsProvider::with_namespace("capi-system");

        let valid = ProviderSpec {
            kubernetes: KubernetesSpec {
                version: "1.32.0".to_string(),
                cert_sans: None,
                bootstrap: BootstrapProvider::Kubeadm,
            },
            config: ProviderConfig::aws(test_aws_config()),
            credentials_secret_ref: None,
        };
        assert!(provider.validate_spec(&valid).await.is_ok());

        let invalid = ProviderSpec {
            kubernetes: KubernetesSpec {
                version: "invalid".to_string(),
                cert_sans: None,
                bootstrap: BootstrapProvider::Kubeadm,
            },
            config: ProviderConfig::aws(test_aws_config()),
            credentials_secret_ref: None,
        };
        assert!(provider.validate_spec(&invalid).await.is_err());
    }

    #[tokio::test]
    async fn validates_required_aws_fields() {
        let provider = AwsProvider::with_namespace("capi-system");

        let mut cfg = test_aws_config();
        cfg.region = String::new();

        let spec = ProviderSpec {
            kubernetes: KubernetesSpec {
                version: "1.32.0".to_string(),
                cert_sans: None,
                bootstrap: BootstrapProvider::Kubeadm,
            },
            config: ProviderConfig::aws(cfg),
            credentials_secret_ref: None,
        };

        let result = provider.validate_spec(&spec).await;
        assert!(result.is_err());
        assert!(result.unwrap_err().to_string().contains("region"));
    }

    #[tokio::test]
    async fn validates_vpc_requires_subnets() {
        let provider = AwsProvider::with_namespace("capi-system");

        let mut cfg = test_aws_config();
        cfg.vpc_id = Some("vpc-12345".to_string());
        // No cp_subnet_ids

        let spec = ProviderSpec {
            kubernetes: KubernetesSpec {
                version: "1.32.0".to_string(),
                cert_sans: None,
                bootstrap: BootstrapProvider::Kubeadm,
            },
            config: ProviderConfig::aws(cfg),
            credentials_secret_ref: None,
        };

        let result = provider.validate_spec(&spec).await;
        assert!(result.is_err());
        assert!(result.unwrap_err().to_string().contains("cpSubnetIds"));
    }

    #[tokio::test]
    async fn supports_rke2_bootstrap() {
        let provider = AwsProvider::with_namespace("capi-system");
        let mut cluster = test_cluster("rke2-test");
        cluster.spec.provider.kubernetes.bootstrap = BootstrapProvider::Rke2;

        let manifests = provider
            .generate_capi_manifests(&cluster, &BootstrapInfo::default())
            .await
            .expect("manifest generation should succeed");

        let cp = manifests
            .iter()
            .find(|m| m.kind.contains("ControlPlane"))
            .expect("ControlPlane should exist");
        assert!(cp.kind.contains("RKE2"));
    }

    #[tokio::test]
    async fn configures_root_volumes() {
        let provider = AwsProvider::with_namespace("capi-system");
        let mut cluster = test_cluster("test");

        if let Some(ref mut cfg) = cluster.spec.provider.config.aws {
            cfg.cp_root_volume_size_gb = Some(100);
            cfg.cp_root_volume_type = Some("io1".to_string());
            cfg.worker_root_volume_size_gb = Some(200);
        }

        let manifests = provider
            .generate_capi_manifests(&cluster, &BootstrapInfo::default())
            .await
            .expect("manifest generation should succeed");

        let cp_template = manifests
            .iter()
            .find(|m| m.kind == "AWSMachineTemplate" && m.metadata.name.contains("control-plane"))
            .expect("control plane template should exist");

        let root_volume = &cp_template.spec.as_ref().expect("spec should exist")["template"]
            ["spec"]["rootVolume"];
        assert_eq!(root_volume["size"], 100);
        assert_eq!(root_volume["type"], "io1");
    }

    #[tokio::test]
    async fn uses_default_iam_profiles() {
        let provider = AwsProvider::with_namespace("capi-system");
        let manifests = provider
            .generate_capi_manifests(&test_cluster("test"), &BootstrapInfo::default())
            .await
            .expect("manifest generation should succeed");

        let cp_template = manifests
            .iter()
            .find(|m| m.kind == "AWSMachineTemplate" && m.metadata.name.contains("control-plane"))
            .expect("control plane template should exist");

        let iam_profile = cp_template.spec.as_ref().expect("spec should exist")["template"]["spec"]
            ["iamInstanceProfile"]
            .as_str()
            .expect("iamInstanceProfile should be a string");
        assert_eq!(
            iam_profile,
            "control-plane.cluster-api-provider-aws.sigs.k8s.io"
        );
    }

    #[tokio::test]
    async fn uses_custom_iam_profiles() {
        let provider = AwsProvider::with_namespace("capi-system");
        let mut cluster = test_cluster("test");

        if let Some(ref mut cfg) = cluster.spec.provider.config.aws {
            cfg.cp_iam_instance_profile = Some("custom-cp-profile".to_string());
            cfg.worker_iam_instance_profile = Some("custom-worker-profile".to_string());
        }

        let manifests = provider
            .generate_capi_manifests(&cluster, &BootstrapInfo::default())
            .await
            .expect("manifest generation should succeed");

        let cp_template = manifests
            .iter()
            .find(|m| m.kind == "AWSMachineTemplate" && m.metadata.name.contains("control-plane"))
            .expect("control plane template should exist");

        let iam_profile = cp_template.spec.as_ref().expect("spec should exist")["template"]["spec"]
            ["iamInstanceProfile"]
            .as_str()
            .expect("iamInstanceProfile should be a string");
        assert_eq!(iam_profile, "custom-cp-profile");

        let worker_template = manifests
            .iter()
            .find(|m| m.kind == "AWSMachineTemplate" && m.metadata.name.contains("md-0"))
            .expect("worker template should exist");

        let worker_iam = worker_template.spec.as_ref().expect("spec should exist")["template"]
            ["spec"]["iamInstanceProfile"]
            .as_str()
            .expect("iamInstanceProfile should be a string");
        assert_eq!(worker_iam, "custom-worker-profile");
    }

    #[tokio::test]
    async fn uses_existing_vpc_when_configured() {
        let provider = AwsProvider::with_namespace("capi-system");
        let mut cluster = test_cluster("test");

        if let Some(ref mut cfg) = cluster.spec.provider.config.aws {
            cfg.vpc_id = Some("vpc-12345".to_string());
            cfg.cp_subnet_ids = Some(vec!["subnet-a".to_string(), "subnet-b".to_string()]);
        }

        let manifests = provider
            .generate_capi_manifests(&cluster, &BootstrapInfo::default())
            .await
            .expect("manifest generation should succeed");

        let aws_cluster = manifests
            .iter()
            .find(|m| m.kind == "AWSCluster")
            .expect("AWSCluster should exist");

        let vpc_id = aws_cluster.spec.as_ref().expect("spec should exist")["network"]["vpc"]["id"]
            .as_str()
            .expect("vpc id should be a string");
        assert_eq!(vpc_id, "vpc-12345");

        let subnets = aws_cluster.spec.as_ref().expect("spec should exist")["network"]["subnets"]
            .as_array()
            .expect("subnets should be an array");
        assert_eq!(subnets.len(), 2);
    }
}
